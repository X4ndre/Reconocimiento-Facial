{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('Reconocimiento_Facial_Modelo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob('Data/Train/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cadena = ''\n",
    "clases = []\n",
    "for i in range(len(folders)):\n",
    "    cadena = ''\n",
    "    for o in folders[i]:\n",
    "        cadena = cadena + o\n",
    "        if(cadena == 'Data/Train\\\\'):\n",
    "            cadena = ''\n",
    "    clases.append(cadena)\n",
    "print(clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "def face_extractor(img):\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    print(faces)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Recorta todas las caras\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _, frame = video_capture.read()\n",
    "    face=face_extractor(frame)\n",
    "    tecla = cv2.waitKey(0)\n",
    "    if tecla==ord('9'):\n",
    "        if type(face) is np.ndarray:\n",
    "            face = cv2.resize(face, (224, 224))\n",
    "            print(f'Face: {face.shape}')\n",
    "            face_rgb = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "            print(f'face_rgb: {face_rgb.shape}')\n",
    "            img_array = np.expand_dims(face_rgb, axis=0)\n",
    "            print(f'img_array 2: {img_array.shape}')\n",
    "            plt.imshow(face_rgb, cmap=plt.cm.binary)\n",
    "            plt.show()\n",
    "            pred = model.predict(img_array)\n",
    "            print(f'Predicci√≥n: {pred}')\n",
    "                     \n",
    "            name=\"None matching\"\n",
    "            print(f'Pred:{pred}')\n",
    "            res = pred.argmax(1)[0]\n",
    "            if(res!=-1):\n",
    "                name=clases[res]\n",
    "                print(name)\n",
    "                cv2.putText(frame,name, (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        \n",
    "        else:\n",
    "            cv2.putText(frame,\"No se encontro ningun rostro\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "    elif tecla==ord('8'):\n",
    "        break\n",
    "    cv2.imshow('Video', frame)\n",
    "    \n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
